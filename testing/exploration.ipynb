{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b5331c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Review_ID  Rating Year_Month     Reviewer_Location  \\\n",
       " 0  670772142       4     2019-4             Australia   \n",
       " 1  670682799       4     2019-5           Philippines   \n",
       " 2  670623270       4     2019-4  United Arab Emirates   \n",
       " 3  670607911       4     2019-4             Australia   \n",
       " 4  670607296       4     2019-4        United Kingdom   \n",
       " \n",
       "                                          Review_Text               Branch  \n",
       " 0  If you've ever been to Disneyland anywhere you...  Disneyland_HongKong  \n",
       " 1  Its been a while since d last time we visit HK...  Disneyland_HongKong  \n",
       " 2  Thanks God it wasn   t too hot or too humid wh...  Disneyland_HongKong  \n",
       " 3  HK Disneyland is a great compact park. Unfortu...  Disneyland_HongKong  \n",
       " 4  the location is not in the city, took around 1...  Disneyland_HongKong  ,\n",
       " ['Review_ID',\n",
       "  'Rating',\n",
       "  'Year_Month',\n",
       "  'Reviewer_Location',\n",
       "  'Review_Text',\n",
       "  'Branch'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded DisneylandReviews.csv file\n",
    "file_path = \"/Users/lianzou/Desktop/Learning Everything/Disney-itinerary/data/DisneylandReviews.csv\"\n",
    "df = pd.read_csv(file_path, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Display the first few rows and column names to understand the structure\n",
    "df.head(), df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8fa950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CA = df[df['Branch'] == 'Disneyland_California'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2960c926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lianzou/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9620</th>\n",
       "      <td>This place has always been and forever will be...</td>\n",
       "      <td>place always forever special feeling get enter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9621</th>\n",
       "      <td>A great day of simple fun and thrills. Bring c...</td>\n",
       "      <td>great day simple fun thrills bring cash nothin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9622</th>\n",
       "      <td>All and all a great day was had. The crowds ar...</td>\n",
       "      <td>great day crowds huge ride times sometimes min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9623</th>\n",
       "      <td>Having been to the Florida location numerous t...</td>\n",
       "      <td>florida location numerous times years didnt kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9624</th>\n",
       "      <td>Had the 4 day pass, spent 3 at DL and one at C...</td>\n",
       "      <td>day pass spent dl one ca great place visit bac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Review_Text  \\\n",
       "9620  This place has always been and forever will be...   \n",
       "9621  A great day of simple fun and thrills. Bring c...   \n",
       "9622  All and all a great day was had. The crowds ar...   \n",
       "9623  Having been to the Florida location numerous t...   \n",
       "9624  Had the 4 day pass, spent 3 at DL and one at C...   \n",
       "\n",
       "                                         Cleaned_Review  \n",
       "9620  place always forever special feeling get enter...  \n",
       "9621  great day simple fun thrills bring cash nothin...  \n",
       "9622  great day crowds huge ride times sometimes min...  \n",
       "9623  florida location numerous times years didnt kn...  \n",
       "9624  day pass spent dl one ca great place visit bac...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK stopwords if not already available\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Define stopwords and basic text preprocessing\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_review(text):\n",
    "    text = str(text).lower()  # lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # remove punctuation and numbers\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # remove stopwords\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "df_CA[\"Cleaned_Review\"] = df_CA[\"Review_Text\"].apply(preprocess_review)\n",
    "\n",
    "# Show a sample of cleaned reviews\n",
    "df_CA[[\"Review_Text\", \"Cleaned_Review\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6f34dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CA = df_CA[df_CA['Year_Month'] != \"missing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05cb0876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CA.drop(columns=['Branch'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b5d98f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>Reviewer_Location</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9620</th>\n",
       "      <td>670801367</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United States</td>\n",
       "      <td>This place has always been and forever will be...</td>\n",
       "      <td>place always forever special feeling get enter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9621</th>\n",
       "      <td>670760708</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United States</td>\n",
       "      <td>A great day of simple fun and thrills. Bring c...</td>\n",
       "      <td>great day simple fun thrills bring cash nothin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9622</th>\n",
       "      <td>670565072</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-5</td>\n",
       "      <td>Australia</td>\n",
       "      <td>All and all a great day was had. The crowds ar...</td>\n",
       "      <td>great day crowds huge ride times sometimes min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9623</th>\n",
       "      <td>670544335</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United States</td>\n",
       "      <td>Having been to the Florida location numerous t...</td>\n",
       "      <td>florida location numerous times years didnt kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9624</th>\n",
       "      <td>670472278</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Had the 4 day pass, spent 3 at DL and one at C...</td>\n",
       "      <td>day pass spent dl one ca great place visit bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28499</th>\n",
       "      <td>92494269</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Myself, along with my two chidren ages 8 and 1...</td>\n",
       "      <td>along two chidren ages visited disneyland cali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28500</th>\n",
       "      <td>92313324</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-12</td>\n",
       "      <td>United States</td>\n",
       "      <td>We love Disneyland so much that we go there of...</td>\n",
       "      <td>love disneyland much go often lately service a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28501</th>\n",
       "      <td>91799423</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-10</td>\n",
       "      <td>Australia</td>\n",
       "      <td>As this was part of our international conferen...</td>\n",
       "      <td>part international conference little spoilt ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28502</th>\n",
       "      <td>91657810</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-12</td>\n",
       "      <td>Australia</td>\n",
       "      <td>we spent one day at disneyland withmy sister  ...</td>\n",
       "      <td>spent one day disneyland withmy sister enough ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28503</th>\n",
       "      <td>91619113</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-12</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Waited 40 years to go to Disneyland and finall...</td>\n",
       "      <td>waited years go disneyland finally dream came ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18202 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Review_ID  Rating Year_Month Reviewer_Location  \\\n",
       "9620   670801367       5     2019-4     United States   \n",
       "9621   670760708       5     2019-4     United States   \n",
       "9622   670565072       4     2019-5         Australia   \n",
       "9623   670544335       5     2019-4     United States   \n",
       "9624   670472278       5     2019-4            Canada   \n",
       "...          ...     ...        ...               ...   \n",
       "28499   92494269       1    2010-12            Canada   \n",
       "28500   92313324       4    2010-12     United States   \n",
       "28501   91799423       5    2010-10         Australia   \n",
       "28502   91657810       4    2010-12         Australia   \n",
       "28503   91619113       5    2010-12         Australia   \n",
       "\n",
       "                                             Review_Text  \\\n",
       "9620   This place has always been and forever will be...   \n",
       "9621   A great day of simple fun and thrills. Bring c...   \n",
       "9622   All and all a great day was had. The crowds ar...   \n",
       "9623   Having been to the Florida location numerous t...   \n",
       "9624   Had the 4 day pass, spent 3 at DL and one at C...   \n",
       "...                                                  ...   \n",
       "28499  Myself, along with my two chidren ages 8 and 1...   \n",
       "28500  We love Disneyland so much that we go there of...   \n",
       "28501  As this was part of our international conferen...   \n",
       "28502  we spent one day at disneyland withmy sister  ...   \n",
       "28503  Waited 40 years to go to Disneyland and finall...   \n",
       "\n",
       "                                          Cleaned_Review  \n",
       "9620   place always forever special feeling get enter...  \n",
       "9621   great day simple fun thrills bring cash nothin...  \n",
       "9622   great day crowds huge ride times sometimes min...  \n",
       "9623   florida location numerous times years didnt kn...  \n",
       "9624   day pass spent dl one ca great place visit bac...  \n",
       "...                                                  ...  \n",
       "28499  along two chidren ages visited disneyland cali...  \n",
       "28500  love disneyland much go often lately service a...  \n",
       "28501  part international conference little spoilt ex...  \n",
       "28502  spent one day disneyland withmy sister enough ...  \n",
       "28503  waited years go disneyland finally dream came ...  \n",
       "\n",
       "[18202 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0d751bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Cleaned_Review  sentiment  Rating\n",
      "9620  place always forever special feeling get enter...     0.7845       5\n",
      "9621  great day simple fun thrills bring cash nothin...     0.9595       5\n",
      "9622  great day crowds huge ride times sometimes min...     0.8402       4\n",
      "9623  florida location numerous times years didnt kn...     0.9624       5\n",
      "9624  day pass spent dl one ca great place visit bac...     0.4939       5\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get sentiment score\n",
    "def get_sentiment(text):\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    return sentiment['compound']  # Sentiment score\n",
    "\n",
    "# Apply sentiment analysis to the review text\n",
    "df_CA['sentiment'] = df_CA['Cleaned_Review'].apply(get_sentiment)\n",
    "\n",
    "# Check the dataframe with sentiment scores\n",
    "print(df_CA[['Cleaned_Review', 'sentiment', \"Rating\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "386f88e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Cleaned_Review  cluster\n",
      "9620  place always forever special feeling get enter...        0\n",
      "9621  great day simple fun thrills bring cash nothin...        0\n",
      "9622  great day crowds huge ride times sometimes min...        3\n",
      "9623  florida location numerous times years didnt kn...        2\n",
      "9624  day pass spent dl one ca great place visit bac...        3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df_CA['Cleaned_Review'])\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "df_CA['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Check the clusters\n",
    "print(df_CA[['Cleaned_Review', 'cluster']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14ba26b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Cleaned_Review  similarity_score  \\\n",
      "9620  place always forever special feeling get enter...          0.000000   \n",
      "9621  great day simple fun thrills bring cash nothin...          0.000000   \n",
      "9622  great day crowds huge ride times sometimes min...          0.050567   \n",
      "9623  florida location numerous times years didnt kn...          0.020473   \n",
      "9624  day pass spent dl one ca great place visit bac...          0.080083   \n",
      "\n",
      "      cluster  \n",
      "9620        0  \n",
      "9621        0  \n",
      "9622        3  \n",
      "9623        2  \n",
      "9624        3  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assume 'user_input' contains the user's preferences as a string\n",
    "user_input = \"I want relaxing rides with positive reviews.\"\n",
    "\n",
    "# Convert user input to TF-IDF features\n",
    "user_input_vector = vectorizer.transform([user_input])\n",
    "X_text = vectorizer.fit_transform(df_CA['Cleaned_Review'])\n",
    "\n",
    "# Calculate similarity between user input and all reviews in the dataset\n",
    "similarity_scores = cosine_similarity(user_input_vector, X_text)\n",
    "\n",
    "# Add similarity scores to the dataframe\n",
    "df_CA['similarity_score'] = similarity_scores.flatten()\n",
    "\n",
    "# Sort the dataframe by similarity score (highest first)\n",
    "df_sorted = df_CA.sort_values(by='similarity_score', ascending=False)\n",
    "\n",
    "# Show the top 5 reviews that are most similar to the user's input\n",
    "print(df_CA[['Cleaned_Review', 'similarity_score', 'cluster']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c9c72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_numeric = df_CA[['sentiment', \"Rating\"]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_numeric)\n",
    "\n",
    "# Combine the text and numeric features\n",
    "from scipy.sparse import hstack\n",
    "X_combined = hstack([X_text, X_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c069d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: disneyland, time, great, park, fun, rides, love, kids, place, day, family, visit, year, disney, food, loved, experience, like, old, amazing, lines, went, good, years, trip, really, going, people, crowded, days, best, crowds, worth, staff, times, long, fireworks, parade, wonderful, magical, little, wait, clean, enjoy, new, expensive, christmas, lots, children, enjoyed, characters, make, ride, dont, friendly, attractions, busy, say, come, halloween, night, awesome, california, lot, way, better, kid, sure, got, th, things, magic, parks, happy, recommend, ages, visited, took, young, didnt, cast, fantastic, nice, think, week, shows, season, special, early, adventure, daughter, need, adults, prices, feel, birthday, definitely, line, money, especially, spent, memories, blast, weather, helpful, pass, bad, age, members, world, service, know, parades, bit, beautiful, favorite, bring, closed, big, holiday, mickey, spend, want, child, try, visiting, thing, water, hours, theme, life, hot, small, vacation, able, plan, im, said, price, party, eat, stay, places, disappointed, perfect, decorations, getting, walk, tickets, expected, passes, main, weekend, walking, wish, summer, land, truly, ive, waiting, hotel, annual, street, super, yes, matter, atmosphere, plenty, different, husband, son, right, high, wanted, pretty, fastpass, break, wasnt, couple, adult, came, coming, queues, fast, anniversary, light, absolutely, friends, watch, excellent, short, thought, star, holidays, huge, expect, quite, live, minutes, entertainment, area, gets, course, pricey, ones, overall, crowd, doesnt, makes, cost, hour, avoid, seeing, employees, leave, pm, wife, end, away, second, original, school, miss, used, families, parking, felt, ticket, pay, look, free, open, minute, taking, disneyworld, evening, hard, character, packed, ago, remember, seen, mouse, let, inside, gone, castle, help, soon, anaheim, restaurants, cool, dream, work, use, options, princesses, needs, older, childhood, spring, youre, entire, past, extremely, highly, watching, werent, return, home, buy, morning, easy, theres, forget, kind, cars, thats, saw, restaurant, extra, left, wars, meet, probably, looking, pirates, run, rest, wont, true, far, pictures, fantasmic, photos, customer, dinner, liked, told, spectacular, snacks, event, check, haunted, brought, minnie, fabulous, kept, half, stayed, forward, save, heart, month, grandchildren, enjoyable, daughters, planning, close, celebration, shops, stop, actually, walt, prepared, strollers, person, crazy, parents, breakfast, lunch, attraction, exciting, havent, member, grand, group, glad, quality, thank, overpriced, real, maybe, possible, making, peak, wrong, tired, twice, months, usual, changed, single, smile, areas, spot, october, longer, missed, totally, late, decorated, plus, waits, lights, mickeys, excited, sit, priced, tour, youll, surprised, afternoon, grandkids, moment, girls, guests, hopper, joy, security, taken, lifetime, mansion, disappointing, started, drinks, room, photo, stuff, believe, admission, stand, incredible, treat, stroller, music, visits, rude, number, blue, value, la, large, attention, review, entrance, paint, face, wow, chance, outside, trying, july, meeting, shoes, mid, entry, list, bayou, feeling, southern, fact, queue, later, friday, lost, younger, ok, unfortunately, ca, walked, trips, waited, candy, impressed, travel, lives, disappoint, grew, start, favourite, classic, beat, finally, safe, including, point, monday, drink, princess, near, usually, guess, smaller, dining, trick, experiences, eyes, shopping, train, bought, weve, care, memorable, saturday, fan, complaint, granddaughter, hope, firework, visitors, managed, available, ahead, ready, standing, offer, problem, orleans, brings, looked, thanks, opened, ask, ridiculous, sad, lovely, choices, january, wdw, heat, display, yr, town, working, lived, despite, given, change, dreams\n",
      "Cluster 1: earth, happiest, reason, called, isnt, app, september, expectations, certainly, whats, mind, seriously, dislike, smiling, absolute, wouldnt, id, job, says, cleanest, alike, mountain, brilliant, gates, simply, happiness, needed, workers, celebrating, indiana, stars, jones, outstanding, bringing, greatest, ball, goes, smiles, purchased, allow, ups, resort, cream, weekends, grown, space, disappoints, add, penny, lucky, popular, continue, ill, understand, ice, thoroughly, grounds, costs, staying, amusement, future, holders, complain, honestly, peter, laughing, doubt, polite, faces, suggest, definately, details, download, easily, hoppers, recently, sister, wonder, loves, words, literally, paying, holder, hate, december, australia, fault, today, anymore, growing, priceless, lol, happier, miles, mother, effort, grow, troubles, keeping, organised, bucket, opinion, churros, passport, learn, disneys, hey, enjoying, toddlers, socal, pan, appreciate, oh, hands, decided\n",
      "Cluster 2: splash, thunder, matterhorn, caribbean, tours, railroad, hyperspace, jungle, broke, buzz, cruise, favorites, nemo, coaster, florida, roller, house, tomorrowland, carribean, bobsleds, kingdom, lightyear, tower, hit, mtn, finding, orlando, terror, rode, major, fantasyland, thrill, alice, fastpasses, longest, shut, min, mr, mins, themed, broken, arrived, monorail, autopia, updated, refurbishment, wonderland, advantage, maintenance, submarine, riding, dole, rider, dl, quickly, tiki, tea, opening, screamin, nightmare, scary, disappointment, straight, running, wet, shorter, pooh, color, whip, universal, compared, dark, dumbo, boat, head, grizzly, story, snow, problems, opens, jedi, toads, arrive, indian, soarin, wild, using, car, technical, skip, soaring, ate, racers, river, headed, sunday, tuesday, astro, chicken, radiator, winnie, adventures, stuck, downtown, square, frontierland, bigger, advice, gave, dated, maxpass, fp, multiple, boys, tried, toontown, similar, bobsled, paris\n",
      "Cluster 3: max, option, enter, book, phone, allowed, idea, paid, tip, waste, gate, works, worked, online, instead, track, tips, unless, purchase, access, allows, certain, wear, quick, advance, springs, average, view, research, pick, spending, easier, reservations, picture, helped, map, tell, helps, deal, closing, ended, cut, till, choose, sun, takes, moving, middle, order, saves, comfortable, knew\n",
      "Cluster 4: size, compare, fl, hotels, fans, prefer, coast, history, compact, comparison, differences, property, version, youve, unique, east, feels, experienced, charm, dw, walts, unlike, nearly, built, difference, comparing, st, location, variety, knows, west, heard, manageable, navigate, scale, distance, set, choice, studios, organized, larger, familiar, case, numerous, notice, site, laid, opportunity, spread, teens\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Get feature names (words) from the TF-IDF vectorizer\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "# Function to get the top N words for each cluster\n",
    "def get_top_words_for_clusters_no_duplicates(kmeans, X, top_n=500):\n",
    "    top_words = {}\n",
    "    all_words = set()  # To keep track of words already used across clusters\n",
    "    \n",
    "    for cluster_num in range(kmeans.n_clusters):\n",
    "        # Get the indices of the words with the highest TF-IDF scores for this cluster\n",
    "        cluster_center = kmeans.cluster_centers_[cluster_num]\n",
    "        top_word_indices = cluster_center.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        # Get the corresponding words\n",
    "        top_words_in_cluster = feature_names[top_word_indices]\n",
    "        \n",
    "        # Remove words that have already appeared in other clusters\n",
    "        unique_words = [word for word in top_words_in_cluster if word not in all_words]\n",
    "        \n",
    "        # Add these words to the set of all words to avoid duplication\n",
    "        all_words.update(unique_words)\n",
    "        \n",
    "        top_words[cluster_num] = unique_words\n",
    "    \n",
    "    return top_words\n",
    "\n",
    "# Get the top 10 unique words for each cluster\n",
    "top_words_no_duplicates = get_top_words_for_clusters_no_duplicates(kmeans, X_combined)\n",
    "\n",
    "# Display the top unique words for each cluster\n",
    "for cluster_num, words in top_words_no_duplicates.items():\n",
    "    print(f\"Cluster {cluster_num}: {', '.join(words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c409d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Cleaned_Review  cluster  \\\n",
      "9620  place always forever special feeling get enter...        0   \n",
      "9621  great day simple fun thrills bring cash nothin...        0   \n",
      "9622  great day crowds huge ride times sometimes min...        3   \n",
      "9623  florida location numerous times years didnt kn...        2   \n",
      "9624  day pass spent dl one ca great place visit bac...        3   \n",
      "\n",
      "                       cluster_name  \n",
      "9620  General Disneyland Experience  \n",
      "9621  General Disneyland Experience  \n",
      "9622   Practical Tips and Logistics  \n",
      "9623     Thrill and Adventure Rides  \n",
      "9624   Practical Tips and Logistics  \n"
     ]
    }
   ],
   "source": [
    "cluster_names = {\n",
    "    0: \"General Disneyland Experience\",\n",
    "    1: \"Positive Sentiment & Happiness\",\n",
    "    2: \"Thrill and Adventure Rides\",\n",
    "    3: \"Practical Tips and Logistics\",\n",
    "    4: \"Hotels and Resort Experience\"\n",
    "}\n",
    "\n",
    "# Map the cluster labels to their respective names\n",
    "df_CA['cluster_name'] = df_CA['cluster'].map(cluster_names)\n",
    "\n",
    "# Display the DataFrame with the new cluster names\n",
    "print(df_CA[['Cleaned_Review', 'cluster', 'cluster_name']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba29e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_map = {\n",
    "    1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June',\n",
    "    7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'\n",
    "}\n",
    "\n",
    "df_CA[['Year', 'Month']] = df['Year_Month'].str.split('-', expand=True)\n",
    "df_CA['Month_Name'] = df_CA['Month'].astype(int).map(month_map)  # Convert month number to name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "540f3635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CA.drop(columns=[\"similarity_score\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a760e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CA.Month = df_CA.Month.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b587b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tag_preferences_from_text(df):\n",
    "    keyword_map = {\n",
    "        # Family Composition\n",
    "        'tag_has_children': [\n",
    "            r'\\b(kids?|children|little ones|toddlers?|babies|youngsters?|brought the kids|family-friendly|stroller|high chair|naps?|play area|girls|boys|kiddie rides?)\\b'\n",
    "        ],\n",
    "        'tag_has_teenagers': [\n",
    "            r'\\b(teenagers?|teens?|preteens?|older kids?|high school age|my teenager|brought our teen|teen-approved|teen-friendly)\\b'\n",
    "        ],\n",
    "\n",
    "        # Accessibility and Special Needs\n",
    "        'tag_needs_guest_services': [\n",
    "            r'\\b(guest services|wheelchair|rent(ed)? (a )?(scooter|ecv)|mobility (aid|device|issue|support)|assistance|accompanied by caregiver|accessibility|disabled|accessible entrance|medical device|walker|scooter accessible|injury|broken leg)\\b'\n",
    "        ],\n",
    "        'tag_needs_accommodations': [\n",
    "            r'\\b(autism|asd|adhd|sensory (issues|needs|friendly)|stimulating|anxiety|panic attack|accommodation(s)?|special needs|neurodivergent|quiet space|disability pass|DAS|guest assistance|mental health|stim toy)\\b'\n",
    "        ],\n",
    "\n",
    "        # Sensory/Emotional Needs\n",
    "        'tag_prefers_quiet': [\n",
    "            r'\\b(quiet(er)?|peaceful|calm(er)?|less crowded|not crowded|not too loud|low noise|escape the noise|break from the crowds|crowd-averse|needed a break|introvert|sensory break|less stimulation)\\b'\n",
    "        ],\n",
    "\n",
    "        # Visitor Origin\n",
    "        'tag_international_visitor': [\n",
    "            r'\\b(flew in|from (abroad|overseas|europe|canada|australia|asia|uk|england|mexico|brazil|france|japan|another country)|international visitor|visiting from overseas|foreign trip|long flight|traveled internationally)\\b'\n",
    "        ],\n",
    "\n",
    "        # Timing and Seasonality\n",
    "        'tag_peak_season_visitor': [\n",
    "            r'\\b(spring break|holiday (week|season)|summer vacation|Christmas week|Halloween night|President(’s|s)? Day|Labor Day|Fourth of July|New Year(\\'s)?|peak season|very crowded|long lines|school break|packed day|busy holiday)\\b'\n",
    "        ],\n",
    "        'tag_special_event_attendee': [\n",
    "            r'\\b(oogie boogie bash|mickey’s not-so-scary|halloween party|star wars nite|villains nite|sweethearts nite|grad nite|throwback nite|princess nite|disney after dark|ticketed event|night event|special event|exclusive event)\\b'\n",
    "        ],\n",
    "        'tag_early_or_late_arrival': [\n",
    "            r'\\b(rope drop|got there at [0-9]+(am| a\\.m\\.)|arrived early|arrived late|missed (fireworks|show)|stayed until closing|early access|entered at night|after dark|morning arrival|closed the park)\\b'\n",
    "        ],\n",
    "\n",
    "        # Budget Sensitivity\n",
    "        'tag_budget_conscious': [\n",
    "            r'\\b(expensive|pricey|overpriced|budget|affordable|cost too much|worth the money|not worth (it|$[0-9]+)|splurged|too much money|cheap(er)?|budget-friendly|financially prepared|high cost|save money)\\b'\n",
    "        ],\n",
    "\n",
    "        # Dietary Preferences\n",
    "        'tag_dietary_restrictions': [\n",
    "            r'\\b(gluten[- ]?free|vegan|vegetarian|nut allergy|peanut allergy|dairy[- ]?free|lactose intolerant|kosher|halal|allergy-friendly|food allergy|celiac|dietary restriction|food sensitivity|food-safe|ingredient list)\\b'\n",
    "        ],\n",
    "        'tag_foodie_focus': [\n",
    "            r'\\b(foodie|snacks?|ate at|blue bayou|lamplight lounge|tiki juice bar|dole whip|beignets?|turkey leg|corn dog|mac and cheese cone|tried everything|best meal|loved the food|restaurant|dining|reservation for food|food experience|eating was a highlight|character dining|festival of holidays|food & wine|flavors of disneyland|seasonal snacks)\\b'\n",
    "        ],\n",
    "\n",
    "        # Ride Preferences\n",
    "        'tag_thrill_seeker': [\n",
    "            r'\\b(thrill ride|roller coaster|intense|fast|scary|adrenaline|drop ride|space mountain|incredicoaster|tower of terror|guardians|radiator springs racers|big thunder|expedition|loop|screamer|splash mountain|scarier|heart-pounding)\\b'\n",
    "        ],\n",
    "        'tag_relaxed_rider': [\n",
    "            r'\\b(scenic ride|relaxing|slow ride|nostalgic|small world|storybook|jungle cruise|peter pan|canoes|train ride|carousel|gentle|calm|peaceful ride|good for relaxing|good break ride|classic ride|nostalgic favorite|kids\\' ride)\\b'\n",
    "        ],\n",
    "\n",
    "        # Visitor History\n",
    "        'tag_first_time_visitor': [\n",
    "            r'\\b(first time|never been|bucket list|always wanted to go|finally went|first visit|first trip|brand new experience|first-timer|first-timers|rookie|newbie)\\b'\n",
    "        ],\n",
    "        'tag_frequent_visitor': [\n",
    "            r'\\b(annual passholder|AP|magic key|we go every year|we always|returning|back again|multiple times|frequent guest|local visitor|season pass|regulars|recurring visitor)\\b'\n",
    "        ],\n",
    "\n",
    "        # Planning Style\n",
    "        'tag_planner': [\n",
    "            r'\\b(genie\\+|lightning lane|LL strategy|planned our (day|route)|itinerary|schedule|reserving (rides|restaurants)|well-organized|mobile order|disney app|timed things|efficiency|used an app|virtual queue|planned ahead|strategized|maximizing time)\\b'\n",
    "        ],\n",
    "        'tag_go_with_the_flow': [\n",
    "            r'\\b(no plan|winged it|just wandered|improvised|walked around|no schedule|took it slow|explored freely|didn’t plan|unstructured|spontaneous|meandered|let the day unfold)\\b'\n",
    "        ],\n",
    "\n",
    "        # Weather and Comfort\n",
    "        'tag_weather_sensitive': [\n",
    "            r'\\b(too hot|heat stroke|sunburn|rained|cold|freezing|hot day|warm weather|rainy day|wore poncho|bad weather|weather ruined|umbrella|sun was brutal|misting fan|needed AC|cooling off|shade break|hydrated|sweaty|humid|soaked)\\b'\n",
    "        ],\n",
    "\n",
    "        # Rest/Break Needs\n",
    "        'tag_needs_rest_breaks': [\n",
    "            r'\\b(tired|needed rest|found a bench|took a break|sat down|rested|break time|overwhelmed|needed to recharge|long day|nursing station|baby center|took it slow|relaxed mid-day|too exhausting|nap break|quiet area|out of energy|midday break|rested feet)\\b'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Apply the tags\n",
    "    for tag, patterns in keyword_map.items():\n",
    "        df[tag] = df['Review_Text'].str.lower().apply(\n",
    "            lambda text: int(any(re.search(p, text) for p in patterns))\n",
    "        )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb185348",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CA_tags = tag_preferences_from_text(df_CA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aeae4f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CA.to_csv(\"~/Downloads/DisneylandReviews_CA.tsv\", sep='\\t', index=False, encoding='utf-8')\n",
    "df_CA_tags.to_csv(\"~/Downloads/DisneylandReviews_CA_tags.tsv\", sep='\\t', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f632f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CA_tags.to_csv(\"DisneylandReviews_CA_tags_pipe.csv\", index=False, sep='|', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
